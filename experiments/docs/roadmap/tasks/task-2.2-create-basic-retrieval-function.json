{
  "type": "Task",
  "status": "todo",
  "project": "CogniMemorySystem-POC",
  "name": "Create Basic Retrieval Function",
  "description": "Implement a function/method to perform semantic search against the indexed MemoryBlocks using the LlamaIndex vector store.",
  "implementation_details": {
    "target_file": "experiments/src/memory_system/llama_memory.py",
    "test_file": "experiments/src/memory_system/test_llama_memory.py"
  },
  "action_items": [
    "[ ] Define method signature in `LlamaMemory` class: `def query_vector_store(self, query_text: str, top_k: int = 5) -> List[NodeWithScore]:` (adjust return type if needed).",
    "[ ] Ensure the method accesses the initialized LlamaIndex `VectorStoreIndex` instance held by the `LlamaMemory` class.",
    "[ ] Use the index's query engine (`index.as_query_engine()`) to retrieve nodes based on `query_text` and `top_k`.",
    "[ ] Return the list of retrieved LlamaIndex `NodeWithScore` objects.",
    "[ ] (TDD) Add tests to `test_llama_memory.py`.",
    "[ ] (TDD) Write test: Use `memory_block_to_node` (from 2.1) to create a node, index it using `LlamaMemory.add_nodes`, then call `query_vector_store` with relevant text and assert the original node ID is retrieved with a high score."
  ],
  "test_criteria": [
    "[ ] Unit/Integration tests pass for `LlamaMemory.query_vector_store`.",
    "[ ] Test confirms that indexing a `MemoryBlock` (via the node converter) and then querying with relevant text retrieves the correct `NodeWithScore` (checking ID and score > threshold).",
    "[ ] Test confirms that querying with irrelevant text does *not* retrieve the indexed block or returns it with a significantly lower score."
  ],
  "success_criteria": [
    "[ ] The `LlamaMemory` class has a method that can perform semantic search against the LlamaIndex vector store.",
    "[ ] Tests demonstrate a basic index -> query -> retrieval loop works for semantic similarity."
  ],
  "current_status": "Task definition created."
} 