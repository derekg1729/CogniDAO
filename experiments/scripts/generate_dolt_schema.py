#!/usr/bin/env python3

"""Purpose: Generate static CREATE TABLE schema for Dolt database initialization.

This script generates the base table structure for the CogniMemorySystem-POC project:
- memory_blocks: Primary table for storing memory blocks
- block_links: For storing relationships between blocks
- node_schemas: For schema registry and versioning
- block_proofs: For tracking operation history with commit hashes

Note: This script does NOT manage versioned metadata type schemas inside node_schemas table.
For dynamic node type schema registration and management, use dolt_schema_manager.py instead.

Future Enhancement TODO: Replace static SQL with dynamic generation based on MemoryBlock and BlockLink Pydantic models.
"""

import os


def generate_schema_sql(output_path: str):
    """Generate the static Dolt SQL schema for database initialization.

    This function creates a schema.sql file with CREATE TABLE statements for the base tables.
    These tables form the foundation of the memory system and are not meant to be modified
    by the dynamic schema management system.

    Args:
        output_path: The file path to write the generated schema to.
    """
    sql_content = """-- Auto-generated from MemoryBlock schema. Do not edit manually.
-- This file should ideally be generated by experiments/scripts/generate_dolt_schema.py
-- based on the Pydantic models in experiments/src/memory_system/schemas/.

CREATE TABLE memory_blocks (
  id VARCHAR(255) PRIMARY KEY, -- Using VARCHAR based on Task 1.4 findings
  type TEXT NOT NULL CHECK (type IN ('knowledge', 'task', 'project', 'doc')),
  text TEXT NOT NULL,
  tags_json JSON,          -- Stores MemoryBlock.tags
  metadata_json JSON,      -- Stores MemoryBlock.metadata
  confidence_json JSON,    -- Stores MemoryBlock.confidence
  source_file TEXT,
  source_uri TEXT,
  created_by TEXT,
  created_at DATETIME,
  updated_at DATETIME,
  embedding TEXT,          -- Added to store vector embeddings (if needed)
  schema_version INT NULL  -- Added in Task 2.0, links to node_schemas.schema_version
);

CREATE TABLE block_links (
  from_id VARCHAR(255) NOT NULL, -- Using VARCHAR based on Task 1.4 findings
  to_id VARCHAR(255) NOT NULL,   -- Using VARCHAR based on Task 1.4 findings
  relation VARCHAR(255) NOT NULL, -- Using VARCHAR based on Task 1.4 findings; Should use canonical types from MemoryBlock.links[].relation
  PRIMARY KEY (from_id, to_id, relation),
  FOREIGN KEY (from_id) REFERENCES memory_blocks(id) ON DELETE CASCADE,
  FOREIGN KEY (to_id) REFERENCES memory_blocks(id) ON DELETE CASCADE
);

-- Added in Task 2.0
CREATE TABLE node_schemas (
  node_type VARCHAR(255) NOT NULL, -- Corresponds to MemoryBlock.type (e.g., 'task', 'project')
  schema_version INT NOT NULL,     -- Version number for this schema
  json_schema JSON NOT NULL,       -- The actual JSON schema output from Pydantic model.model_json_schema()
  created_at DATETIME NOT NULL,    -- When this schema version was registered
  PRIMARY KEY (node_type, schema_version)
);

-- Added in Task 7.2 (block_proofs creation); updated in Task 3.1.2 (standardized operation field and added index on block_id)
CREATE TABLE block_proofs (
  id INTEGER PRIMARY KEY AUTO_INCREMENT,
  block_id VARCHAR(255) NOT NULL,
  commit_hash VARCHAR(255) NOT NULL,
  operation VARCHAR(10) NOT NULL CHECK (operation IN ('create', 'update', 'delete')),
  timestamp DATETIME NOT NULL,
  INDEX block_id_idx (block_id)
);

-- Future considerations mentioned in project plan might add:
-- ALTER TABLE memory_blocks ADD COLUMN status VARCHAR(50); 
"""
    try:
        # Ensure the directory exists
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # Write the schema to the file
        with open(output_path, "w") as f:
            f.write(sql_content)
        print(f"[✓] Wrote complete schema to: {output_path}")
        return True
    except IOError as e:
        print(f"[✗] Error writing schema to {output_path}: {e}")
        return False


def main():
    """Main function that determines the output path and generates the schema."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(script_dir, "..", "dolt_data", "schema.sql")
    success = generate_schema_sql(output_path)

    if success:
        print("Static Dolt table schema generation completed successfully.")
        print("Generated base tables: memory_blocks, block_links, node_schemas, block_proofs")
        print("Note: For dynamic metadata schema management, use dolt_schema_manager.py")
    else:
        print("Schema generation failed.")


if __name__ == "__main__":
    main()
