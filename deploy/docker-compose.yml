services:
  # Dolt SQL Server Database Service
  dolt-db:
    image: ${DOLT_IMAGE:-deploy-dolt-db}
    build:
      context: ..
      dockerfile: services/dolt_memory/cogni-cogni-dao-memory.dockerfile
    env_file: ./.env
    environment:
      - HOST=0.0.0.0
      - PORT=3306
      - DOLT_ROOT_PATH=/.dolt
      - DATABASE_REMOTE=https://doltremoteapi.dolthub.com/cogni/cogni-dao-memory
      - DATABASE_NAME=cogni-dao-memory
      - DOLTHUB_USER=cogni
      - DOLTHUB_EMAIL=steward@cognidao.org
      - DATA_DIR=/dolthub-dbs/cogni/cogni-dao-memory
      - DOLT_ROOT_HOST=%
      - DOLT_ROOT_PASSWORD=${DOLT_ROOT_PASSWORD}
      - CREDS_KEY=g3ld8if3kr1kl5ajm6ptl1kii5hvgo1t6vka5ms02arv2
      - CREDS_VALUE=${DOLTHUB_JWK_CREDENTIAL}
    volumes:
      - dolt_data:/dolthub-dbs
    ports:
      - "3306:3306"
    healthcheck:
      test: ["CMD", "dolt", "sql", "-q", "SELECT 1;"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - cogni-net

  # Redis Service for LangGraph Checkpointing (DEV/TEST ENVIRONMENT)
  redis:
    image: redis/redis-stack-server:latest
    command: redis-server --maxmemory 512mb --maxmemory-policy noeviction --appendonly yes --auto-aof-rewrite-percentage 100 --auto-aof-rewrite-min-size 64mb
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
    volumes:
      - redis_data:/data  # Keep dev data persistent for convenience. Long-term: consider removing for truly ephemeral testing
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - cogni-net

  # PostgreSQL Service for LangGraph Server Runtime
  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_DB=langgraph
      - POSTGRES_USER=langgraph
      - POSTGRES_PASSWORD=langgraph
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langgraph"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - cogni-net

  # Web API Service  
  api:
    image: ${API_IMAGE:-cogni-api-local}
    build:
      context: ..
      dockerfile: services/web_api/Dockerfile.api
    env_file: ./.env
    environment:
      - DOLT_HOST=dolt-db
      - DOLT_PORT=3306
      - DOLT_USER=root
      - DOLT_PASSWORD=${DOLT_ROOT_PASSWORD}
      - DOLT_DATABASE=cogni-dao-memory
      - DOLT_REMOTE_URL=https://doltremoteapi.dolthub.com/cogni/cogni-dao-memory
      - DOLT_REMOTE_PASSWORD=${DOLTHUB_MCP_ACCESS_WRITE}
      # ToolHive API URL for MCP tool health checking
      - TOOLHIVE_API=http://toolhive:8080
    ports: ["8000:8000"]  # Direct access for deploy script compatibility
    depends_on:
      dolt-db:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/healthz')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - cogni-net

  caddy:
    image: caddy:2-alpine
    ports: ["80:80", "443:443"]
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    depends_on: [api]
    networks:
      - cogni-net

  # Prefect Server with SQLite
  prefect-server:
    image: prefecthq/prefect:3-python3.12
    command: prefect server start --host 0.0.0.0
    environment:
      - PREFECT_UI_URL=http://localhost:4200
      - PREFECT_API_URL=http://localhost:4200/api
      - PREFECT_SERVER_API_HOST=0.0.0.0
      - PREFECT_SERVER_API_PORT=4200
    ports:
      - "4200:4200"  # Direct access like you're used to
    volumes:
      - prefect_data:/root/.prefect  # Persist SQLite database
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:4200/api/health')"]
      interval: 30s
      retries: 3
    networks:
      - cogni-net

  # Prefect Worker - connects to containerized Prefect server
  prefect-worker:
    image: ${PREFECT_WORKER_IMAGE:-cogni-prefect-worker-local}
    build:
      context: ..
      dockerfile: services/prefect_worker/Dockerfile.prefect-worker
    command: prefect worker start --pool cogni-pool
    env_file: ./.env
    environment:
      - PREFECT_API_URL=http://prefect-server:4200/api
      # ToolHive API URL for MCP tool access
      - TOOLHIVE_API=http://toolhive:8080
      # OpenAI API Key for AutoGen flows (explicit override)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Helicone observability configuration (sitecustomize.py will auto-configure OpenAI SDK)
      - HELICONE_API_KEY=${HELICONE_API_KEY}
      - HELICONE_BASE_URL=${HELICONE_BASE_URL:-https://oai.helicone.ai/v1}
    depends_on:
      prefect-server:
        condition: service_healthy
    volumes:
      - ../:/workspace  # Mount the entire project for flow access
      - ./.env:/workspace/.env  # Explicitly mount .env file
    working_dir: /workspace
    restart: unless-stopped
    networks:
      - cogni-net

  # ToolHive - MCP container orchestrator  
  toolhive:
    image: ghcr.io/stacklok/toolhive:latest
    container_name: toolhive
    command: ["serve", "--host", "0.0.0.0", "--port", "8080"]  # Bind to all interfaces
    user: "0:0"  # Run as root for Docker socket access on macOS
    networks:
      - cogni-net
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:rw
    environment:
      - DOCKER_NETWORK=deploy_cogni-net
      - THV_SECRETS_BACKEND=1password
      - THV_NO_UPDATES=1  # Prevent version checks to avoid startup lag
    ports:
      - "8080:8080"  # Use ToolHive's default port 8080
      # MCP server ports are dynamically managed by ToolHive when servers are deployed
    restart: unless-stopped

  # LangGraph Combined Service (cogni_presence + playwright_poc)
  langgraph-cogni-presence:
    image: ${LANGGRAPH_COMBINED_IMAGE:-cogni-langgraph-combined-local}
    env_file: ./.env
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
      - REDIS_URI=redis://redis:6379
      - DATABASE_URI=postgresql://langgraph:langgraph@postgres:5432/langgraph
      - COGNI_MCP_URL=http://toolhive:24160/sse
      - PLAYWRIGHT_MCP_URL=http://toolhive:24162/sse
      - PREFECT_API_URL=http://prefect-server:4200/api
      - LOG_LEVEL=debug
      # MCP Client Reconnection Configuration
      - MCP_MAX_RETRIES=5
      - MCP_HEALTH_CHECK_INTERVAL=30.0
      - MCP_CONNECTION_TIMEOUT=30.0
    ports:
      - "8002:8000"  # Both graphs accessible via same service (Web API connects here)
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      toolhive:
        condition: service_started
    restart: unless-stopped
    networks:
      - cogni-net

volumes:
  caddy_data:
  caddy_config:
  dolt_data:
  prefect_data:
  mcp_chroma:
  redis_data:

networks:
  cogni-net:
    driver: bridge 