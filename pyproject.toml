[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "cogni"
version = "0.1.0"
description = "Adapter layers for integrating Cogni's memory system with various AI frameworks"
authors = [
    { name = "CogniDAO" }
]
dependencies = [
    "crewai>=0.121.1",
    "llama-index>=0.10,<=0.12.32",
    "doltpy",
    "rpds-py",
    # LangGraph and MCP Integration (Phase 1: Basic LangGraph)
    "langgraph>=0.3.0,<0.6.0",  # Latest stable LangGraph with MCP support
    "langchain-mcp-adapters>=0.1.0,<0.2.0",  # Official MCP adapters for LangChain
    "langchain-core>=0.3.0",  # Core LangChain functionality
    "langchain-openai>=0.2.0",  # OpenAI integration
    "openai>=1.0.0,<1.80.0",  # OpenAI client
]
requires-python = ">=3.9"

[project.optional-dependencies]
autogen = ["autogen-core"]

[tool.hatch.build.targets.wheel]
packages = ["infra_core", "cogni_adapters", "legacy_logseq", "schemas"]

[tool.ruff]
line-length = 100
exclude = ["build", "dist", ".venv", "__pycache__"]

[tool.ruff.lint]
select = ["E", "F"]        # Enable basic style + logical error checks
ignore = ["E501"]          # Ignore line length for now 

[tool.uv.workspace]
members = [
    "services/mcp_server",
]

[tool.uv.sources]
cogni = { workspace = true }

[dependency-groups]
dev = [
    "cogni",
]
