#!/usr/bin/env python3
"""
Test file to check SQL queries for tag filtering in Dolt.
"""

import logging
import json
from doltpy.cli import Dolt
from infra_core.constants import MEMORY_DOLT_ROOT

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


def test_direct_sql_query():
    """Test direct SQL query with JSON_CONTAINS for tag filtering."""
    # Initialize Dolt repo
    repo = Dolt(MEMORY_DOLT_ROOT)

    # Run the query
    query = """
    SELECT id, type, tags 
    FROM memory_blocks 
    WHERE JSON_CONTAINS(tags, '"core-document"')
    """
    logger.info(f"Running direct SQL query: {query}")
    result = repo.sql(query=query, result_format="json")

    # Verify results exist
    assert result and "rows" in result, "SQL query returned no results structure"
    assert result["rows"], "No core-document tagged blocks found with direct SQL query"

    # Log results
    logger.info(f"Direct SQL query found {len(result['rows'])} results:")
    for row in result["rows"]:
        logger.info(f"Block: {row['id']}, Type: {row['type']}, Tags: {row['tags']}")
        # Verify that each result has the core-document tag
        assert "core-document" in row["tags"], f"Block {row['id']} missing core-document tag"


def test_python_function_sql():
    """Test SQL queries that would be generated by read_memory_blocks_by_tags."""
    # Initialize Dolt repo
    repo = Dolt(MEMORY_DOLT_ROOT)

    # Generate SQL as in read_memory_blocks_by_tags
    tags = ["core-document"]
    match_all = True
    branch = "main"

    # Construct WHERE clause based on tags
    where_clauses = []
    for tag in tags:
        # Escape tag for JSON_CONTAINS
        escaped_tag_for_json = json.dumps(tag)
        escaped_tag_for_sql = "'" + escaped_tag_for_json.replace("'", "''") + "'"
        where_clauses.append(f"JSON_CONTAINS(tags, {escaped_tag_for_sql})")

    clause_separator = " AND " if match_all else " OR "
    full_where_clause = clause_separator.join(where_clauses)

    # Version that uses AS OF clause (main branch)
    query_with_branch = f"""
    SELECT
        id, type, schema_version, text, tags, metadata,
        source_file, source_uri, confidence, created_by, created_at, updated_at
    FROM memory_blocks
    AS OF '{branch}'
    WHERE {full_where_clause}
    """

    # Version that queries from working set (no AS OF clause)
    query_working_set = f"""
    SELECT
        id, type, schema_version, text, tags, metadata,
        source_file, source_uri, confidence, created_by, created_at, updated_at
    FROM memory_blocks
    WHERE {full_where_clause}
    """

    # Try both queries
    logger.info(f"Running SQL query with branch: {query_with_branch}")
    result_with_branch = repo.sql(query=query_with_branch, result_format="json")

    logger.info(f"Running SQL query on working set: {query_working_set}")
    result_working_set = repo.sql(query=query_working_set, result_format="json")

    # Check results from branch query
    branch_results = []
    if result_with_branch and "rows" in result_with_branch and result_with_branch["rows"]:
        branch_results = result_with_branch["rows"]
        logger.info(f"Branch-based query found {len(branch_results)} results:")
        for row in branch_results:
            logger.info(f"Block: {row['id']}, Type: {row['type']}, Tags: {row['tags']}")

    # Check results from working set query
    working_set_results = []
    if result_working_set and "rows" in result_working_set and result_working_set["rows"]:
        working_set_results = result_working_set["rows"]
        logger.info(f"Working set query found {len(working_set_results)} results:")
        for row in working_set_results:
            logger.info(f"Block: {row['id']}, Type: {row['type']}, Tags: {row['tags']}")

    # Main assertions
    # Either branch or working set should have results
    assert branch_results or working_set_results, (
        "No core-document blocks found in either branch or working set"
    )

    # If there's a difference between branch and working set, log it
    if len(branch_results) != len(working_set_results):
        logger.info(
            f"DIFFERENCE DETECTED: Branch has {len(branch_results)} blocks, working set has {len(working_set_results)} blocks"
        )

    # Store branch results and working set results for test_tag_sql_consistency
    # but do this in a way that doesn't cause pytest warnings
    test_python_function_sql.branch_results = branch_results
    test_python_function_sql.working_set_results = working_set_results


def test_tag_sql_consistency():
    """Test consistency between different SQL approaches."""
    # Initialize Dolt repo for direct test
    repo = Dolt(MEMORY_DOLT_ROOT)

    # Run direct SQL query again
    direct_query = """
    SELECT id, type, tags 
    FROM memory_blocks 
    WHERE JSON_CONTAINS(tags, '"core-document"')
    """
    direct_result = repo.sql(query=direct_query, result_format="json")
    direct_results = direct_result["rows"] if direct_result and "rows" in direct_result else []

    # Get results from previous test via function attributes
    # If the previous test wasn't run, execute it now
    if not hasattr(test_python_function_sql, "branch_results"):
        test_python_function_sql()

    branch_results = test_python_function_sql.branch_results
    working_set_results = test_python_function_sql.working_set_results

    # Compare results
    logger.info("\n=== Comparing results ===")
    logger.info(f"Direct SQL query: {len(direct_results)} results")
    logger.info(f"Python-generated branch query: {len(branch_results)} results")
    logger.info(f"Python-generated working set query: {len(working_set_results)} results")

    # Check the escaping
    tag = "core-document"
    escaped_json = json.dumps(tag)
    logger.info(f"Original tag: {tag}")
    logger.info(f"JSON-escaped: {escaped_json}")
    logger.info(f"Expected SQL query part: JSON_CONTAINS(tags, {escaped_json})")

    # Assert consistency between approaches
    # The direct query and at least one of the Python-generated queries should return results
    assert len(direct_results) > 0, "Direct SQL query should return results"

    # If there's a discrepancy, it should be between branch and working set
    if len(branch_results) == 0 and len(working_set_results) > 0:
        logger.info(
            "ISSUE IDENTIFIED: Core documents exist in the working set but not in the 'main' branch."
        )
        logger.info(
            "FIX: Commit the changes to the 'main' branch or modify read_memory_blocks_by_tags to use the working set."
        )
    elif len(direct_results) > 0 and len(branch_results) == 0 and len(working_set_results) == 0:
        assert False, "SQL query format in read_memory_blocks_by_tags is incorrect"
